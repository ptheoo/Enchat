import requests
from bs4 import BeautifulSoup
import pymongo
import sys
import hashlib

def get_mongo_collection():
    client = pymongo.MongoClient("mongodb://localhost:27017/")
    db = client["grammar_db"]
    return db["grammar_articles"]

def extract_main_content(soup):
    # C√°c selector ph·ªï bi·∫øn cho ph·∫ßn n·ªôi dung ch√≠nh
    possible_selectors = [
        "article",
        "#main",
        "#content",
        ".content",
        ".main-content",
        ".post-content",
        ".entry-content"
    ]
    for sel in possible_selectors:
        el = soup.select_one(sel)
        if el:
            return el.get_text(separator="\n", strip=True)
    # N·∫øu kh√¥ng c√≥ th√¨ fallback to√†n b·ªô body
    return soup.body.get_text(separator="\n", strip=True) if soup.body else ""

def crawl_page(url):
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        
        title = soup.title.string.strip() if soup.title else "No title"
        text_content = extract_main_content(soup)
        
        if not text_content or len(text_content) < 50:
            print(f"‚ö†Ô∏è N·ªôi dung qu√° ng·∫Øn ho·∫∑c tr·ªëng cho {url}")
        
        return {
            "_id": hashlib.md5(url.encode()).hexdigest(),
            "url": url,
            "title": title,
            "content": text_content,
            "length": len(text_content)
        }
    except Exception as e:
        print(f"‚ùå L·ªói crawl {url}: {e}")
        return None

def main(source_file):
    col = get_mongo_collection()
    
    with open(source_file, "r", encoding="utf-8") as f:
        for line in f:
            url = line.strip()
            if not url:
                continue
            print(f"üåê ƒêang t·∫£i: {url}")
            data = crawl_page(url)
            if data:
                try:
                    col.insert_one(data)
                    print(f"üì• L∆∞u v√†o MongoDB: {data['title']} ({data['length']} k√Ω t·ª±)")
                except pymongo.errors.DuplicateKeyError:
                    print(f"‚ö†Ô∏è B·ªè qua (ƒë√£ t·ªìn t·∫°i): {url}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("C√°ch d√πng: python crawl_grammar.py urls.txt")
    else:
        main(sys.argv[1])
